{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Lag Aggregate</h1>\n",
    "\n",
    "Aggregate fact table in interval slices against a base table that defines keys and temporal cutoff dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pyrasgo\n",
    "!pip install pyrasgo --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspaces/RasgoUDTs/python', '/workspaces/RasgoUDTs', '/workspaces/RasgoUDTs/python', '/workspaces/RasgoUDTs', '/workspaces/RasgoUDTs/table_transforms/lag_aggregate', '/usr/local/lib/python37.zip', '/usr/local/lib/python3.7', '/usr/local/lib/python3.7/lib-dynload', '', '/home/vscode/.local/lib/python3.7/site-packages', '/usr/local/lib/python3.7/site-packages', '/home/vscode/.local/lib/python3.7/site-packages/IPython/extensions', '/home/vscode/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# basic setup\n",
    "# use your rasgo API key to connect\n",
    "import pyrasgo\n",
    "api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIyMzIiLCJpZCI6MjMyLCJvcmdJZCI6bnVsbCwidXNlcm5hbWUiOiJtaXJvQHVudGl0bGVkLXJlc2VhcmNoLmNvbSIsImV4cCI6NTM4NTkyNjI2NTV9.Fo1CgctXnWbfxrjb-xq-m-NQBVDO1YDbYkDlpQiXjCM\"\n",
    "rasgo = pyrasgo.connect(api_key)\n",
    "\n",
    "# transform constants\n",
    "TRANSFORM_NAME=\"lag_aggregate\"\n",
    "TRANSFORM_TYPE=\"table\"\n",
    "TRANSFORM_YAML_PATH=\"/workspaces/RasgoUDTs/table_transforms/lag_aggregate/lag_aggregate.yaml\"\n",
    "\n",
    "# have to add this due to import errors - utils should be maybe part of package ?\n",
    "import sys\n",
    "sys.path.insert(0,\"/workspaces/RasgoUDTs\")\n",
    "sys.path.insert(0,\"/workspaces/RasgoUDTs/python\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate lagging sales features for given customer base\n",
    "\n",
    "- Replicating directive work with transforms\n",
    "- Test transform experience\n",
    "- Understand transform authoring concepts and experience\n",
    "\n",
    "Data:\n",
    "\n",
    "**Base dataset**:\n",
    "All customers with every date of purchase from 2013-01-01 to 2013-12-31\n",
    "\n",
    "**Lag aggregates**:\n",
    "Sum of sales from Internet Sales for various intervals prior to every purchase date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available transforms\n",
    "# Best place to see more info is https://docs.rasgoml.com/rasgo-docs/pyrasgo/user-defined-transforms-udts\n",
    "transforms = rasgo.get.transforms()\n",
    "for t in transforms:\n",
    "    args = []\n",
    "    for a in t.arguments:\n",
    "        args.append(a['name'])\n",
    "    print(t.id, t.name, '({})'.format(', '.join(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transform\n",
    "from python.utils import parse_transform_args_from_yaml, get_transform_source_code, _read_yaml\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# Had to rip this out of the utils to execute\n",
    "# Whats the expectation regarding how end user will be able to iterate on transform implementation ?\n",
    "# Not the best experience, writing jinja without IDE help/context is pretty hard\n",
    "# Whats the transform lifecycle from user's perspective\n",
    "# Deleted and recreated transform probably 50 times to get it right\n",
    "# Utils should probably be integrated into pyrasgo proper\n",
    "# Adding a pyrasgo function to be able to create and recreate a single transform might help\n",
    "# Helper function so I can just do transform = ..., transform.publish(status='draft',overwrite=true) or something ?\n",
    "# Transform status: draft, published or .. to help with lifecycle ?? \n",
    "\n",
    "source_code = get_transform_source_code(TRANSFORM_TYPE,TRANSFORM_NAME)\n",
    "transform_yml = _read_yaml(TRANSFORM_YAML_PATH)\n",
    "transform_args = parse_transform_args_from_yaml(transform_yml)\n",
    "print(f\"Source code length: {len(source_code)}\")\n",
    "\n",
    "transform = rasgo.create.transform(\n",
    "                    name=TRANSFORM_NAME,\n",
    "                    type=TRANSFORM_TYPE,\n",
    "                    source_code=source_code,\n",
    "                    arguments=transform_args\n",
    "                )\n",
    "print(transform.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete transform\n",
    "transform.id\n",
    "rasgo.delete.transform(transform.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rasgo data sources to operate on\n",
    "sales = rasgo.get.data_source(id=2637)\n",
    "customers = rasgo.get.data_source(id=2616)\n",
    "dates = rasgo.get.data_source(id=2617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview raw data\n",
    "rasgo.read.source_data(dates.id, limit=100).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an base dataset (observation) - Customers with purchase dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "Internal API Error when making POST request\n\nStatus Code: 400\n\nInternal Error Details: {'message': 'Error parsing template to query string', 'error': 'not enough values to unpack (expected 3, got 1)'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyrasgo/api/connection.py\u001b[0m in \u001b[0;36m_raise_internal_api_error_if_any\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.rasgoml.com/v1/transform/sql",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_549/3509800761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mjoin_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'INNER'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0msource_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ORDERDATEKEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mjoin_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATEKEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m ).preview()\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyrasgo/utils/transforms.py\u001b[0m in \u001b[0;36mpreview\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Get the transform SQL and set limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtransform_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreview_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mtransform_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{transform_sql} LIMIT {limit}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyrasgo/utils/transforms.py\u001b[0m in \u001b[0;36mpreview_sql\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         transform_sql = self._post(resource=\"/transform/sql\",\n\u001b[1;32m    113\u001b[0m                                    \u001b[0m_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude_unset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                                    api_version=1).json()\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform_sql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyrasgo/api/connection.py\u001b[0m in \u001b[0;36m_post\u001b[0;34m(self, resource, _json, params, api_version)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                  \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                  params=params or {})\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_internal_api_error_if_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyrasgo/api/connection.py\u001b[0m in \u001b[0;36m_raise_internal_api_error_if_any\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0merr_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             raise APIError(\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0;34mf\"Internal API Error when making {response.request.method} request\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                 \u001b[0;34mf\"Status Code: {response.status_code}\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;34mf\"Internal Error Details: {err_details}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIError\u001b[0m: Internal API Error when making POST request\n\nStatus Code: 400\n\nInternal Error Details: {'message': 'Error parsing template to query string', 'error': 'not enough values to unpack (expected 3, got 1)'}"
     ]
    }
   ],
   "source": [
    "# aggregate with the help of a date dimension\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# Join was redeployed and modified in the middle of my run so not sure whats going on in here\n",
    "# Order of transforms should matter and sql should be composed properly\n",
    "# This should work but it fails - changing join to be the 1st transform makes it work\n",
    "# join_table - lets be consistent and align naming convention - are these tables, source or datasets ???\n",
    "\n",
    "sales.transform(\n",
    "   transform_name='filter',\n",
    "   filter_statements=['ORDERDATEKEY BETWEEN 20110101 AND 20111231']\n",
    ").transform(\n",
    "  transform_name='aggregate',\n",
    "  group_items=['CUSTOMERKEY', 'ORDERDATEKEY'],\n",
    "  aggregations={\n",
    "      'CUSTOMERKEY': ['COUNT']\n",
    "  }\n",
    ").transform(\n",
    "  transform_name='join',\n",
    "  join_table=dates.id,\n",
    "  join_type='INNER',\n",
    "  source_columns=['ORDERDATEKEY'],\n",
    "  join_columns=['DATEKEY']\n",
    ").preview()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMERKEY</th>\n",
       "      <th>ORDERDATE</th>\n",
       "      <th>CUSTOMERKEY_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11003</td>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11003</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11003</td>\n",
       "      <td>2013-05-10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUSTOMERKEY  ORDERDATE  CUSTOMERKEY_COUNT\n",
       "0        11003 2010-12-29                  1\n",
       "1        11003 2013-01-05                  4\n",
       "2        11003 2013-05-10                  4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate sales to get every customer and purchase date\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# Avoiding join\n",
    "# Cant to group by without agg value aka simple distinct/group by\n",
    "# Count distinct not possible with current aggregate transform\n",
    "# Want to be able to control column outputs and aliases, this will be madness after 3rd transform\n",
    "\n",
    "base = sales.transform(\n",
    "   transform_name='filter',\n",
    "   #filter_statements=['ORDERDATEKEY BETWEEN 20130101 AND 20131231']\n",
    "   filter_statements=['CUSTOMERKEY = 11003']\n",
    ").transform(\n",
    "  transform_name='aggregate',\n",
    "  group_items=['CUSTOMERKEY', 'ORDERDATE'],\n",
    "  aggregations= {\n",
    "      'CUSTOMERKEY': ['COUNT']\n",
    "  }\n",
    ")\n",
    "# .transform(\n",
    "#   transform_name='join',\n",
    "#   join_table_id=date_dim.id,\n",
    "#   join_type='INNER',\n",
    "#   source_columns=['ORDERDATEKEY'],\n",
    "#   joined_colums=['DATEKEY']\n",
    "# ).\n",
    "\n",
    "base.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>CUSTOMERKEY_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  CUSTOMERKEY_COUNT\n",
       "0  1                  3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count of base dataset for verification\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# Should be able to geta count of base dataset\n",
    "# If additional transform is executed - its added to the transform chain - changing the base\n",
    "# This behavior is confusing - My base assignment was explicit, I did not ask to reassign the variable - just to calculate total count\n",
    "# thats how it works on source , if its a transform chain it works differently \n",
    "# Dont want to reason about - Am I doing transform on source or a dataset it should be fluid - everything is a dataset and b\n",
    "#\n",
    "# 1. source.transform - nothing happens to source - new chain is created, no assignment needed\n",
    "# 2. t1=source.transform - explicit assignment\n",
    "# 3. t1.transform - why should this change t1 ? (it should create a chain like when stat is a source)\n",
    "# 4. t2=t1.transform - this should create and assign new chain to t2\n",
    "# 5. t2.transform - again - should this change t2 or create a new chain\n",
    "\n",
    "base.transform(\n",
    "    transform_name='aggregate',\n",
    "    group_items=[1],\n",
    "    aggregations={\n",
    "        'CUSTOMERKEY': ['COUNT']\n",
    "    }).preview()\n",
    "\n",
    "# my base has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>CUSTOMERKEY_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  CUSTOMERKEY_COUNT\n",
       "0  1                  3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base preview\n",
    "base.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2876\n"
     ]
    }
   ],
   "source": [
    "# publish the new data set back to Rasgo\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# must register a new source in order to be able to anchor my base dataset and start new transform chain\n",
    "# this should be async or promise based or something, wait is > 15s for 2K rows\n",
    "# because of direct db object naming - if someone puts an unsupported character in the name this will break\n",
    "# if I made a mistake I would like an overwrite capability so I dont have to delete and keep track of ids\n",
    "# once ids are lost how can I pull source by name ?\n",
    "# friendly name should be for users and UI not creating db objects\n",
    "# table_name - again confusing naming convention, why should the user be concern about the table name here ? Should be working with an abstraction layer \n",
    "# how is rasgo going to handle naming conflicts ?\n",
    "\n",
    "# delete base source\n",
    "# rasgo.delete.data_source(base_source.id)\n",
    "# following will fail\n",
    "# base_source = base.to_source(new_table_name='customer_sales.._lag_aggregate_base')\n",
    "\n",
    "base_source = base.to_source(new_table_name='customer_sales_lag_aggregate_base')\n",
    "print(base_source.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one time I could not read back source ? cant replicate - was no error just empty dataset\n",
    "base_source.id\n",
    "rasgo.read.source_data(base_source.id, limit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DataSource 2784 successfully deleted'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete base_source on accidental error\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# dont like that I have to keep ids on memory when iterating\n",
    "# the sdk should operate with user defined names or identifiers not internals\n",
    "\n",
    "rasgo.delete.data_source('2784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of base dataset after registering as source\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# fails cause there is no group by\n",
    "# repeated runs add CTEs\n",
    "# with group_items=[1] works because of the rendered sql syntax \"SELECT 1, {AGGS} FROM {RELATION} GROUP BY 1\"\n",
    "# had to add suffix to sources to distinguish\n",
    "\n",
    "base_source.transform(\n",
    "  transform_name='aggregate',\n",
    "  group_items=[1],\n",
    "  aggregations={\n",
    "      'CUSTOMERKEY': ['COUNT']\n",
    "  }\n",
    ").preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT\\n        fct.CUSTOMERKEY,fct.ORDERDATE,\\n                SUM(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '30 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_SUM_30,\\n                AVG(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '30 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_AVG_30,\\n                SUM(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '60 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_SUM_60,\\n                AVG(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '60 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_AVG_60,\\n                SUM(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '90 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_SUM_90,\\n                AVG(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '90 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_AVG_90,\\n                SUM(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '180 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_SUM_180,\\n                AVG(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '180 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_AVG_180,\\n                SUM(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '360 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_SUM_360,\\n                AVG(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '360 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_AVG_360,\\n                SUM(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '720 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_SUM_720,\\n                AVG(\\n                    CASE\\n                        WHEN \\n                            fct.ORDERDATE >= (base.ORDERDATE - INTERVAL '720 DAY')\\n                            AND fct.ORDERDATE < base.ORDERDATE\\n                        THEN SALESAMOUNT \\n                    END) as SALESAMOUNT_AVG_720\\nFROM ADVENTUREWORKS.PUBLIC.FACTINTERNETSALES fct\\nJOIN RASGO.PUBLIC.CUSTOMER_SALES_LAG_AGGREGATE_BASE base\\n    ON fct.CUSTOMERKEY = base.CUSTOMERKEY-- for some strange reason you must leave a blank line here otherwise sql gets squished when rendered\\n\\nGROUP BY\\nfct.ORDERDATE,\\n    fct.CUSTOMERKEY\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add lags for forecast model\n",
    "\n",
    "# ===== Notes & Feedback =====\n",
    "# orientation of base vs fact\n",
    "# can I assign output of transform to dataframe without registering source\n",
    "# how can i preview the entire dataset ?\n",
    "# doing simple count is tedious- requires additional steps\n",
    "\n",
    "\n",
    "sales_lag_aggs = sales.transform(\n",
    "      transform_name='lag_aggregate',\n",
    "      base_source_id=base_source.id,\n",
    "      source_temporal_column='ORDERDATE',\n",
    "      base_temporal_column='ORDERDATE',\n",
    "      source_join_columns=['CUSTOMERKEY'],\n",
    "      base_join_columns=['CUSTOMERKEY'],\n",
    "      aggregations={\n",
    "          'SALESAMOUNT': ['SUM', 'AVG']\n",
    "      },\n",
    "      lag_period_type='DAY',\n",
    "      lag_interval_list=[30,60,90,180,360,720]\n",
    "    )\n",
    "sales_lag_aggs.preview_sql()\n",
    "\n",
    "#\n",
    "#sales_lag_aggs.preview(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMERKEY</th>\n",
       "      <th>ORDERDATE</th>\n",
       "      <th>SALESAMOUNT_SUM_30</th>\n",
       "      <th>SALESAMOUNT_AVG_30</th>\n",
       "      <th>SALESAMOUNT_SUM_60</th>\n",
       "      <th>SALESAMOUNT_AVG_60</th>\n",
       "      <th>SALESAMOUNT_SUM_90</th>\n",
       "      <th>SALESAMOUNT_AVG_90</th>\n",
       "      <th>SALESAMOUNT_SUM_180</th>\n",
       "      <th>SALESAMOUNT_AVG_180</th>\n",
       "      <th>SALESAMOUNT_SUM_360</th>\n",
       "      <th>SALESAMOUNT_AVG_360</th>\n",
       "      <th>SALESAMOUNT_SUM_720</th>\n",
       "      <th>SALESAMOUNT_AVG_720</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11003</td>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11003</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2318.9600</td>\n",
       "      <td>579.7400000000</td>\n",
       "      <td>2318.9600</td>\n",
       "      <td>579.7400000000</td>\n",
       "      <td>2318.9600</td>\n",
       "      <td>579.7400000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11003</td>\n",
       "      <td>2013-05-10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUSTOMERKEY  ORDERDATE SALESAMOUNT_SUM_30 SALESAMOUNT_AVG_30  \\\n",
       "0        11003 2010-12-29               None               None   \n",
       "1        11003 2013-01-05               None               None   \n",
       "2        11003 2013-05-10               None               None   \n",
       "\n",
       "  SALESAMOUNT_SUM_60 SALESAMOUNT_AVG_60 SALESAMOUNT_SUM_90 SALESAMOUNT_AVG_90  \\\n",
       "0               None               None               None               None   \n",
       "1               None               None               None               None   \n",
       "2               None               None               None               None   \n",
       "\n",
       "  SALESAMOUNT_SUM_180 SALESAMOUNT_AVG_180 SALESAMOUNT_SUM_360  \\\n",
       "0                None                None                None   \n",
       "1           2318.9600      579.7400000000           2318.9600   \n",
       "2                None                None                None   \n",
       "\n",
       "  SALESAMOUNT_AVG_360 SALESAMOUNT_SUM_720 SALESAMOUNT_AVG_720  \n",
       "0                None                None                None  \n",
       "1      579.7400000000           2318.9600      579.7400000000  \n",
       "2                None                None                None  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_lag_aggs.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish\n",
    "\n",
    "sales_lag_aggs_source = sales_lag_aggs.to_source(new_table_name='customer_sales_lag_aggregate_final')\n",
    "print(sales_lag_aggs_source.id)\n",
    "\n",
    "sales_lag_aggs_data = rasgo.read.source_data(sales_lag_aggs_source.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to csv\n",
    "sales_lag_aggs.preview(0).to_csv(\"sales_lag_aggs.csv\")\n",
    "#sales_lag_aggs_data.to_csv(\"sales_lag_aggs_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup of all objects\n",
    "if 'base_source' in locals():\n",
    "    rasgo.delete.data_source(base_source.id)\n",
    "if 'sales_lag_aggs_source' in locals():\n",
    "    rasgo.delete.data_source(sales_lag_aggs_source.id)\n",
    "# if 'transform' in locals():\n",
    "#     rasgo.delete.transform(transform.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback summary\n",
    "\n",
    "**Authoring**\n",
    "\n",
    "**Usability**\n",
    "- need many transforms to do simple things (select, aggregate, alias with join)\n",
    "- working with ids is painful\n",
    "  - keeping track if ids (runtime kernel reset or due error can lead to id loss and no easy way to go back or cleanup)\n",
    "  - talking to objects by ids is not ideal\n",
    "  - would prefer managing objects using their user assigned friendly names\n",
    "- like the fluid api idea of .transform but mutation behavior is confusing\n",
    "  - 2 different behaviour models\n",
    "    - running any .transform essentially mutates the underlying dataset (adds an operation to existing chain)\n",
    "    - unless its a source where it does not (of course)\n",
    "    - want explicit control when to assign transform chain to another dataset\n",
    "    - doing simple count is tedious and results in mutating the existing dataset\n",
    "  - behaviour is not following pandas : df.add(1) does not mutate existing df\n",
    "- not able to control output alias\n",
    "  - select * can not be the default\n",
    "  - conflicts unaviodable, especially due to stacked CTEs (ambiguous columns not allowed as CTE output)\n",
    "\n",
    "\n",
    "**Authoring Tranforms**\n",
    "  - Authors are not well supported through the transform authoring procerss\n",
    "    - should there be a transform lifecycle ?\n",
    "      - draft mode while I work out the kinks ?\n",
    "    - want to create or update(overwrite) a single transform at a time\n",
    "      - expect better support from SDK and more seamless experience\n",
    "  - jinja template writing is painful even for a seasoned sql engineer (limited mix of python fns, interpolation, commas on the end etc )\n",
    "    - would welcome some additional functions that are callable inside jinja to do typical repeat stuff\n",
    "      - document available modules and functions inside jinja context\n",
    "      - add additional helper modules/functions to ease some of the dev pain\n",
    "        - generate list of columns or expression with alias pairs with commas etc.\n",
    "      - current looping technique works buts its error prone and not easy to follow\n",
    "  - found myself many times going to the sql editor to lookup something to plug into a transform - that cant be\n",
    "    - need more core sdk support while authoring\n",
    "    - getting dataset meta and types in various forms\n",
    "  - transform arguments universe\n",
    "    - what are my possible argument types ?\n",
    "    - what are the sepcial functions some types offer(column, source etc)\n",
    "    - should have a good base to choose from with spe\n",
    "  - whats the access control model for transform authoring use ?\n",
    "\n",
    "**Other**\n",
    "- dont love the transform organization - row / column / table\n",
    "  - it will be overloaded soon with many many transforms in a group\n",
    "  - min_max_scaler, moving_avg - while they create new columns their operation is very different from a+b as c\n",
    "  - would prefer a more domain specific naming or two way organization\n",
    "  - by domain and by return type (scalar, dataset)\n",
    "- naming convention\n",
    " - is it table, source, dataframe or dataset\n",
    " - follow through in argument naming\n",
    "   - source publishing \"new_table_name\" is a great example\n",
    "   - user should not be naming tables - revealing internals again\n",
    "- sequentail ids are reveal internal implementation details\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
